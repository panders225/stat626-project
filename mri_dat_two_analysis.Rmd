---
title: "Searching for Stationarity"
author: "Philip Anderson; panders2@tamu.edu"
output: pdf_document
---

```{r setup, message=FALSE}
library("astsa")
library("DescTools")
library("GGally")
library("tseries")
```

Objective: I'm going to mess around with some of the Week 3 material - basically looking to see if I can get the autocorrelation function to have no significant lags.

```{r}
# read in the data
mri <- read.csv("/Users/panders2/Documents/schools/tamu/stat_626/project/stat_626_proj/mri_dat_one.csv")
# update field names
names(mri) <- c("hour", "minute", "freq", "int_pressure", "atm_pressure", "tot_pressure", "tesla")
```

With an initial look at the data, I think we need to smooth it to eliminate the abberration at time index ~950.  

```{r}
astsa::tsplot(mri$freq)
```

Zoom in:

```{r}
astsa::tsplot(mri$freq[900:1000])
```

I don't know how much of an impact this outlier will have on any sort of models we build, but it probably isn't good.  Regardless, taking care of it will be a good exercise in smoothing, so let's do it anyway.  The _ksmooth_ function used by the book does not appear to have automatic bandwidth selection, so let's try several and see what happens.

```{r}

astsa::tsplot(mri$freq)
lines(ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=0.5), lwd=1.5, col="blue")
lines(ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=5), lwd=1.5, col="red")
lines(ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=15), lwd=1.5, col="green")

legend("bottomleft", c("bw=0.5", "bw=5", "bw=15"), lwd=rep(1.5, 3) , col=c("blue", "red", "green"))

```

Focusing on just the problem area, it seems that a higher bandwidth does the best job at smoothing this area out.  There may be some concern about over-smoothing, but we can proceed as is.  Once again, let's zoom in.

```{r}
# (I believe) kernel smoothing utilizes the entire array for producing estimates, so we will 
# need to make new variables on the entire set before zooming

mri$freq_point5 <- ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=0.5)$y
mri$freq_5 <- ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=5)$y
mri$freq_15 <- ksmooth(time(mri$freq), mri$freq, kernel="normal", bandwidth=15)$y

astsa::tsplot(mri$freq[900:1000], lwd=2)
lines(mri$freq_point5[900:1000], lwd=1.25, col="blue")
lines(mri$freq_5[900:1000], lwd=1.25, col="red")
lines(mri$freq_15[900:1000], lwd=1.25, col="green")

legend("bottomleft", c("bw=0.5", "bw=5", "bw=15"), lwd=rep(1.5, 3) , col=c("blue", "red", "green"))
```

Kernel smoothing is one viable option - localized regression is another.  Let's do that and compare.  Like the kernel bandwidth parameter, the lowess regressor incorporates a parameter that influences smoothness, (_f_).  It simply measures what proportion of the array points we should use to influence the smooth at each estimation point.

```{r}
astsa::tsplot(mri$freq, lwd=2)
lines(lowess(mri$freq, f=0.1), lwd=1.25, col="blue")
lines(lowess(mri$freq, f=0.2), lwd=1.25, col="purple")
lines(lowess(mri$freq, f=0.5), lwd=1.25, col="red")
lines(lowess(mri$freq, f=1), lwd=1.25, col="green")

legend("bottomleft", c("f=0.1", "f=0.2", "f=0.5", "f=1"), lwd=rep(1.5, 5) , col=c("blue", "purple",  "red", "green"))
```

The kernel smoother hugs the original trend line much more closely than the lowess regression.  I am going to add the f=0.1 and f=0.2 estimations to the data, because they seem more fair than 0.5 or 1.


```{r}
mri$freq_low_1 <- lowess(mri$freq, f=0.1)$y
mri$freq_low_2 <- lowess(mri$freq, f=0.2)$y

```

We now have a handful of smoothed data points.  Let's see if we can get to stationarity using those as our base.  Taking first differences seemed promising in the past so let's do that again.

```{r}
astsa::tsplot(diff(mri$freq))
```

This looks stationary aside from the same problem area, but it may just be an axis thing.  Let's adjust it and revisit. 

```{r}
astsa::tsplot(diff(mri$freq), ylim=c(-1.5,1.5))
```

There looks to be some autocorrelation when we get up close.

```{r}
acf2(diff(mri$freq))
```

It's tough to see in the differenced time series plot, but we do have a strong and significant negative lag at lag 1.  Perhaps the differenced series is an MA(1) model?  We can look at this idea later.

Let's repeat this exercise for some of our smoothed series and see.

```{r}
# kernel smoother with bandwidth of 15
astsa::tsplot(diff(mri$freq_15))
```

Clear trend.

```{r}
acf2(diff(mri$freq_15))
```

Now suggestive of an AR(p) model.

Let's just try the simpler moving average smoother instead of fancy things.

```{r}
# 12 point MA
mri$freq_ma <- stats::filter(mri$freq, sides=2, filter=rep(1/12, 12))
astsa::tsplot(diff(mri$freq_ma))
```

Similar story.

Ironic, but let's add noise to the smoothed series and see if that helps.

```{r}

test <- mri$freq_low_1 + rnorm(length(mri$freq_point5))
astsa::tsplot(test)
astsa::tsplot(diff(test))
acf2(diff(test))
```

That was promising for a brief second.  Let's try _detrending_ instead of differencing.

```{r}
lin_mod <- lm(mri$freq ~ 0 + mri$atm_pressure + mri$int_pressure)
astsa::tsplot(diff(lin_mod$residuals))
acf2(diff(lin_mod$residuals))
```

Note that the MA(q) model ACF cuts off after lag q, while the PACF tails off.  This could related to that.

Detrend with one of the smoothers.

```{r}
lin_mod2 <- lm(mri$freq_point5 ~ time(mri$freq_point5))
astsa::tsplot(diff(lin_mod2$residuals))
acf2(diff(lin_mod2$residuals, differences=2))

```

Suggests MA(2) model.

Split the series into halves and see if anything changes.

```{r}
acf2(diff(mri$freq[1:800]))
acf2(diff(mri$freq[801:1600]))

```

Try structural modeling.

```{r, error=T}
decompose(mri$freq_low_2)
```

Good to know.


